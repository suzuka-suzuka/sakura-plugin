import { GoogleGenAI, Modality } from "@google/genai"
import { getImg } from "../lib/utils.js"
import Setting from "../lib/setting.js"
import sharp from "sharp"

export class EditImage extends plugin {
  constructor() {
    super({
      name: "AIå›¾åƒç¼–è¾‘",
      dsc: "ä½¿ç”¨AIæ¨¡å‹ä¿®æ”¹æˆ–ç”Ÿæˆå›¾ç‰‡",
      event: "message",
      priority: 1135,
      rule: [
        {
          reg: "^i(.*)$",
          fnc: "editImageHandler",
          log: false,
        },
        {
          reg: "^æ‰‹åŠåŒ–$",
          fnc: "figureHandler",
          log: false,
        },
      ],
    })
  }
  get appconfig() {
    return Setting.getConfig("Permission")
  }
  async figureHandler(e) {
    const imageUrls = await getImg(e)
    if (!imageUrls || imageUrls.length === 0) {
      await this.reply("è¯·ä¸Šä¼ éœ€è¦æ‰‹åŠåŒ–çš„å›¾ç‰‡å“¦~", true, { recallMsg: 10 })
      return true
    }

    const promptText =
      "Please turn this photo into a figure. Behind it, there should be a packaging box with a large clear front window, printed character artwork, the product name, logo, barcode, and a small specs or authenticity panel, with a small price tag sticker on one corner of the box. There is also a computer monitor screen at the back, showing the design sketch of the figure. In front of the box, on a round plastic base, place the figure version of the photo I gave you, and the figure must be three-dimensional. Iâ€™d like the PVC material to be clearly represented. It would be even better if the background is indoors."

    return this._processAndCallAPI(e, promptText, imageUrls)
  }

  async editImageHandler(e) {
    const promptText = e.msg.replace(/^i/, "").trim()
    const imageUrls = await getImg(e)

    if (!promptText) {
      await this.reply("è¯·å‘Šè¯‰æˆ‘ä½ æƒ³å¦‚ä½•ä¿®æ”¹å›¾ç‰‡å“¦~ ä¾‹å¦‚ï¼ši å¸®æˆ‘æŠŠèƒŒæ™¯æ¢æˆæµ·æ»©", true, { recallMsg: 10 })
      return true
    }

    return this._processAndCallAPI(e, promptText, imageUrls)
  }

  async _processAndCallAPI(e, promptText, imageUrls) {
    if (!this.appconfig?.enable?.includes(e.sender.user_id)) {
      return false
    }
    await this.reply("ğŸ¨ æ­£åœ¨è¿›è¡Œåˆ›ä½œ, è¯·ç¨å€™...", true, { recallMsg: 10 })

    const contents = []
    const hasImage = imageUrls && imageUrls.length > 0

    if (promptText) {
      contents.push({ text: promptText })
    }

    if (hasImage) {
      for (const imageUrl of imageUrls) {
        try {
          const response = await fetch(imageUrl)
          if (!response.ok) {
            throw new Error(`å›¾ç‰‡ä¸‹è½½å¤±è´¥: ${response.statusText}`)
          }
          const arrayBuffer = await response.arrayBuffer()
          let buffer = Buffer.from(arrayBuffer)
          const contentType = response.headers.get("content-type") || "image/jpeg"
          let finalMimeType = contentType

          if (contentType === "image/gif") {
            buffer = await sharp(buffer).toFormat("png").toBuffer()
            finalMimeType = "image/png"
          }

          const base64Data = buffer.toString("base64")

          contents.push({
            inlineData: {
              mimeType: finalMimeType,
              data: base64Data,
            },
          })
        } catch (error) {
          logger.error("å¤„ç†å…¶ä¸­ä¸€å¼ å›¾ç‰‡æ—¶å‡ºé”™:", error)
          await this.reply("å¤„ç†å…¶ä¸­ä¸€å¼ å›¾ç‰‡æ—¶å¤±è´¥, è¯·æ£€æŸ¥å›¾ç‰‡é“¾æ¥æˆ–ç¨åå†è¯•ã€‚", true, {
            recallMsg: 10,
          })
          return true
        }
      }
    }

    try {
      const GEMINI_MODEL = "gemini-2.5-flash-image-preview"
      const config = Setting.getConfig("Vertex")
      if (!config || !config.PROJECT_ID || !config.LOCATION) {
        throw new Error("é…ç½®é”™è¯¯ï¼šæœªæ‰¾åˆ° 'Vertex' é…ç½®æ–‡ä»¶æˆ–ç¼ºå°‘ PROJECT_ID/LOCATIONã€‚")
      }
      const { PROJECT_ID, LOCATION } = config
      const ai = new GoogleGenAI({
        vertexai: true,
        project: PROJECT_ID,
        location: LOCATION,
      })

      const safetySettings = [
        {
          category: "HARM_CATEGORY_HATE_SPEECH",
          threshold: "OFF",
        },
        {
          category: "HARM_CATEGORY_DANGEROUS_CONTENT",
          threshold: "OFF",
        },
        {
          category: "HARM_CATEGORY_SEXUALLY_EXPLICIT",
          threshold: "OFF",
        },
        {
          category: "HARM_CATEGORY_HARASSMENT",
          threshold: "OFF",
        },
        {
          category: "HARM_CATEGORY_IMAGE_HATE",
          threshold: "OFF",
        },
        {
          category: "HARM_CATEGORY_IMAGE_DANGEROUS_CONTENT",
          threshold: "OFF",
        },
        {
          category: "HARM_CATEGORY_IMAGE_HARASSMENT",
          threshold: "OFF",
        },
        {
          category: "HARM_CATEGORY_IMAGE_SEXUALLY_EXPLICIT",
          threshold: "OFF",
        },
      ]

      const response = await ai.models.generateContent({
        model: GEMINI_MODEL,
        contents: contents,
        config: {
          responseModalities: [Modality.TEXT, Modality.IMAGE],
          safetySettings: safetySettings,
        },
      })

      const imagePart = response.candidates?.[0]?.content?.parts?.find(
        part => part.inlineData && part.inlineData.mimeType.startsWith("image/"),
      )

      if (imagePart) {
        const imageData = imagePart.inlineData.data
        await this.reply(segment.image(`base64://${imageData}`))
      } else {
        const textPart = response.candidates?.[0]?.content?.parts?.find(part => part.text)
        const textResponse = textPart ? textPart.text : "åˆ›ä½œå¤±è´¥"
        await this.reply(`${textResponse}`, true, {
          recallMsg: 10,
        })
      }
    } catch (error) {
      logger.error(`è°ƒç”¨Vertex AIå¤±è´¥:`, error)
      await this.reply("åˆ›ä½œå¤±è´¥ï¼Œå¯èƒ½æ˜¯æœåŠ¡æˆ–é…ç½®é—®é¢˜ã€‚", true, { recallMsg: 10 })
    }

    return true
  }
}
